{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.1.0\n",
      "cuda: True\n",
      "cudnn: True , version: 8902 , bf32: True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch._dynamo\n",
    "\n",
    "from llm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 32\n",
    "    vocab_size: int = 65\n",
    "    n_layer: int = 2\n",
    "    n_head: int = 4\n",
    "    n_embd: int = 80\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "\n",
    "cfg = GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 65\n",
      "Chars: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "with io.open(\"shakespeare.txt\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(set(text))\n",
    "vocabSize = len(chars)\n",
    "print(f\"Vocab size: {vocabSize}\")\n",
    "print(f\"Chars: {''.join(chars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world -> [46 43 50 50 53  1 61 53 56 50 42] -> hello world\n"
     ]
    }
   ],
   "source": [
    "def getEncoder():\n",
    "    maxCharCode = max(map(ord, chars))\n",
    "    char2index = [0] * (maxCharCode + 1)\n",
    "    index2char = [''] * (vocabSize + 1)\n",
    "    for i, ch in enumerate(chars):\n",
    "        char2index[ord(ch)] = i\n",
    "        index2char[i] = ch\n",
    "    def encode(s):\n",
    "        return np.array([char2index[ord(ch)] for ch in s])\n",
    "    def decode(xs):\n",
    "        return ''.join([index2char[i] for i in xs])\n",
    "    return encode, decode\n",
    "encode, decode = getEncoder()\n",
    "\n",
    "print(f\"hello world -> {encode('hello world')} -> {decode(encode('hello world'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: train=(1003854,), validation=(111540,)\n"
     ]
    }
   ],
   "source": [
    "splitIdx = len(text) * 9 // 10\n",
    "trainData, validData = encode(text[:splitIdx]), encode(text[splitIdx:])\n",
    "print(f\"Shapes: train={trainData.shape}, validation={validData.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, data, batchSize, device=device):\n",
    "        self.data = data\n",
    "        self.batchSize = batchSize\n",
    "        self.device = device\n",
    "        self.nChars = len(data)\n",
    "        self.blockSize = cfg.block_size\n",
    "        self.maxRnd = self.nChars - self.blockSize - 1\n",
    "        self.random = random.Random()\n",
    "        self.xs = np.zeros([batchSize,self.blockSize], dtype=np.byte)\n",
    "        self.ys = np.zeros([batchSize,self.blockSize], dtype=np.byte)\n",
    "        self.tensorShape = [batchSize, self.blockSize]\n",
    "        self.charsServed = 0\n",
    "\n",
    "    def StartReproducibleRandom(self):\n",
    "        self.random = random.Random(1337)\n",
    "\n",
    "    def GetBatch(self):\n",
    "        for i in range(self.batchSize):\n",
    "            ix = self.random.randint(0, self.maxRnd)\n",
    "            #xdst = self.xs[i*self.blockSize:(i+1)*self.blockSize]\n",
    "            #xsrc = self.data[ix:ix+self.blockSize]\n",
    "            np.copyto(self.xs[i], self.data[ix:ix+self.blockSize])\n",
    "            ix = ix + 1\n",
    "            np.copyto(self.ys[i], self.data[ix:ix+self.blockSize])\n",
    "\n",
    "        self.charsServed += self.batchSize * self.blockSize\n",
    "\n",
    "        xb = torch.tensor(self.xs, dtype=torch.int64, device=self.device, requires_grad=False)\n",
    "        yb = torch.tensor(self.ys, dtype=torch.int64, device=self.device, requires_grad=False)\n",
    "        return xb, yb\n",
    "\n",
    "    @property\n",
    "    def Epoch(self):\n",
    "        return float(self.charsServed) / float(self.nChars)        \n",
    "    \n",
    "#bg = BatchGenerator(trainData, batchSize=4)\n",
    "#bg.GetBatch()\n",
    "#bg.Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flash sdp enabled = True\n",
      "Number of parameters: 154465\n"
     ]
    }
   ],
   "source": [
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "print(f\"Flash sdp enabled = {torch.backends.cuda.flash_sdp_enabled()}\")\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "\n",
    "model = LanguageModel(cfg.n_layer, cfg.n_head, cfg.n_embd, cfg.vocab_size, cfg.block_size)\n",
    "\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# which model \n",
    "tmodel = model\n",
    "#tmodel = torch.jit.script(model)\n",
    "#tmodel = torch.jit.load(\"shakespeare.pt.zip\")\n",
    "\n",
    "# do you wish to compile it\n",
    "#tmodel = torch.compile(tmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"blah                            R!w\\nP;eH&IRMTRkG:fLozG,-ZBFswT?$?QZ$'T\\nUHY'b3Jr$&ooVqJKFbnuP\\n$pSdRjXpS3SYaGtqSIL?jn.P;Gc:ndN&,h'cQPw\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(model, nTokens, input):\n",
    "    input = input.ljust(model.blockSize, ' ')\n",
    "    if len(input) != model.blockSize:\n",
    "        raise ValueError(f\"Expected input of length {model.blockSize}, got {len(input)}\")\n",
    "    idx = torch.tensor(encode(input).reshape(1,-1), dtype=torch.int64, device=device, requires_grad=False)\n",
    "    idx = idx.expand([2, -1])\n",
    "    idx = generateIxs(model, idx, nTokens)\n",
    "    idx = idx[0].cpu()\n",
    "    ords = [int(idx[i]) for i in range(idx.numel())]\n",
    "    return decode(ords)\n",
    "\n",
    "tmodel.to(device)\n",
    "generate(tmodel, 100, \"blah\") # should render some jibberish on untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.378620624542236, 4.379757881164551)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evalLosses(model):\n",
    "    nLoops = 16\n",
    "    batchSize = 256\n",
    "    trainBatchGen = BatchGenerator(trainData, batchSize)\n",
    "    validBatchGen = BatchGenerator(validData, batchSize)\n",
    "    def getLoss(bg):\n",
    "        bg.StartReproducibleRandom()\n",
    "        losses = [get_loss(model,yb, model.forward(xb)) for i in range(nLoops) for xb, yb in [bg.GetBatch()]]\n",
    "        return torch.stack(losses).mean().item()\n",
    "    return getLoss(trainBatchGen), getLoss(validBatchGen)\n",
    "\n",
    "xb,yb = BatchGenerator(trainData,1).GetBatch()\n",
    "yHat = tmodel(xb)\n",
    "#cmodel.loss(yb, yHat)\n",
    "evalLosses(tmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select optimization features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "#torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "autocast_bfloat16_enabled = False\n",
    "#autocast_bfloat16_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(tmodel.parameters(), lr=0.0001)\n",
    "\n",
    "batch_size = 384\n",
    "batchGen = BatchGenerator(trainData, batch_size)\n",
    "\n",
    "def _train(nSteps):\n",
    "    tmodel.train()\n",
    "    for step in range(nSteps+1):\n",
    "        xb, yb = batchGen.GetBatch()\n",
    "        yHat = tmodel.forward(xb)\n",
    "        loss = get_loss(tmodel, yb, yHat)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step % 5000 == 0 or step == nSteps:\n",
    "            tmodel.eval()\n",
    "            trainLoss, validLoss = evalLosses(tmodel)\n",
    "            print(f\"Step {step:5d}: loss={loss.item():6f} train={trainLoss:6f} valid={validLoss:6f} epoch={batchGen.Epoch:.2f}\")\n",
    "            tmodel.train()\n",
    "\n",
    "def train_with_autocast(nSteps):\n",
    "    with autocast(dtype=torch.bfloat16):\n",
    "        _train(nSteps)\n",
    "\n",
    "if autocast_bfloat16_enabled:\n",
    "    train = train_with_autocast\n",
    "else:\n",
    "    train = _train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0: loss=4.384702 train=4.361674 valid=4.362899 epoch=0.01\n",
      "Step  2000: loss=2.075950 train=2.088111 valid=2.130675 epoch=24.49\n",
      "w                               solcust,\n",
      "Gall, your grprit.\n",
      "Y I Cleare, ave the\n",
      "\n",
      "ICHARGSCORK:\n",
      "Jespe ond thand viy, is yom any nurdy:\n"
     ]
    }
   ],
   "source": [
    "# warm up (for jit compiler)\n",
    "train(2000)\n",
    "\n",
    "print(generate(tmodel,100, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0: loss=2.094636 train=2.087728 valid=2.130200 epoch=24.51\n",
      "Step  5000: loss=1.748007 train=1.752620 valid=1.905648 epoch=85.71\n",
      "Step 10000: loss=1.656689 train=1.642814 valid=1.826207 epoch=146.91\n",
      "Step 15000: loss=1.590245 train=1.585738 valid=1.779402 epoch=208.12\n",
      "Step 20000: loss=1.560660 train=1.547022 valid=1.751709 epoch=269.32\n",
      "Step 25000: loss=1.557401 train=1.520464 valid=1.735263 epoch=330.53\n",
      "Step 30000: loss=1.492872 train=1.501572 valid=1.722801 epoch=391.73\n",
      "Step 35000: loss=1.477246 train=1.484621 valid=1.711440 epoch=452.93\n",
      "Step 40000: loss=1.496978 train=1.472062 valid=1.706427 epoch=514.14\n",
      "Step 45000: loss=1.485065 train=1.460302 valid=1.703026 epoch=575.34\n",
      "Step 50000: loss=1.449751 train=1.450073 valid=1.699020 epoch=636.55\n",
      "CPU times: user 4min 38s, sys: 1.07 s, total: 4min 39s\n",
      "Wall time: 4min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# do the actual training (measure time)\n",
    "\n",
    "train(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M                               love go?\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "My lanted, in this eye, here glady, if is life;\n",
      "Herefor patience; stable?\n",
      "\n",
      "RICHMOND:\n",
      "Good speak him, being loyal here:\n",
      "Let I hadfort-way, is though in Chrives here I lightly is,\n",
      "Lord; let he bawlinges? Henry, patiemen\n",
      "To hear at me trive.\n",
      "My life,\n",
      "Forgive him. The did Barnary that in the agentle the rucket my soon the sensult and lords.\n",
      "\n",
      "Clown:\n",
      "That night measter, Richard:\n",
      "Base you, give grant.\n",
      "\n",
      "Provost:\n",
      "Peapay is no most galler? her soul pass to persuive you?\n",
      "Upon my s\n"
     ]
    }
   ],
   "source": [
    "print(generate(tmodel, 500, \"M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model...\n",
      "LanguageModel(\n",
      "  (layers): Sequential(\n",
      "    (embed): EmbeddingModel(\n",
      "      (tok_emb): Embedding(65, 80)\n",
      "      (pos_emb): Embedding(32, 80)\n",
      "    )\n",
      "    (block1): Block(\n",
      "      (ln1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): CausalSelfAttention(\n",
      "        (c_attn): Linear(in_features=80, out_features=240, bias=False)\n",
      "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ln2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (net): Sequential(\n",
      "          (c_fc): Linear(in_features=80, out_features=320, bias=False)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=320, out_features=80, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (block2): Block(\n",
      "      (ln1): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): CausalSelfAttention(\n",
      "        (c_attn): Linear(in_features=80, out_features=240, bias=False)\n",
      "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ln2): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): MLP(\n",
      "        (net): Sequential(\n",
      "          (c_fc): Linear(in_features=80, out_features=320, bias=False)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=320, out_features=80, bias=False)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (de_embed): Linear(in_features=80, out_features=65, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# save the model if you were training base Model(), rather than a model loaded from file or compiled\n",
    "if tmodel == model:\n",
    "    print(\"saving model...\")\n",
    "    tmodel.to(torch.device(\"cpu\"))\n",
    "    tmodel.eval()\n",
    "    save_model = torch.jit.script(tmodel)\n",
    "    save_model.save(\"shakespeare.pt.zip\")\n",
    "    print(model)\n",
    "    model.to(device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
