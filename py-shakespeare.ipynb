{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.1.0\n",
      "cuda: True\n",
      "cudnn: True , version: 8902 , bf32: True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch._dynamo\n",
    "\n",
    "from llm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GPTConfig:\n",
    "    block_size: int = 32\n",
    "    vocab_size: int = 65\n",
    "    n_layer: int = 2\n",
    "    n_head: int = 4\n",
    "    n_embd: int = 80\n",
    "    dropout: float = 0.0\n",
    "    bias: bool = True # True: bias in Linears and LayerNorms, like GPT-2. False: a bit better and faster\n",
    "\n",
    "cfg = GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 65\n",
      "Chars: \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "with io.open(\"shakespeare.txt\", mode=\"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(set(text))\n",
    "vocabSize = len(chars)\n",
    "print(f\"Vocab size: {vocabSize}\")\n",
    "print(f\"Chars: {''.join(chars)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world -> [46 43 50 50 53  1 61 53 56 50 42] -> hello world\n"
     ]
    }
   ],
   "source": [
    "def getEncoder():\n",
    "    maxCharCode = max(map(ord, chars))\n",
    "    char2index = [0] * (maxCharCode + 1)\n",
    "    index2char = [''] * (vocabSize + 1)\n",
    "    for i, ch in enumerate(chars):\n",
    "        char2index[ord(ch)] = i\n",
    "        index2char[i] = ch\n",
    "    def encode(s):\n",
    "        return np.array([char2index[ord(ch)] for ch in s])\n",
    "    def decode(xs):\n",
    "        return ''.join([index2char[i] for i in xs])\n",
    "    return encode, decode\n",
    "encode, decode = getEncoder()\n",
    "\n",
    "print(f\"hello world -> {encode('hello world')} -> {decode(encode('hello world'))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: train=(1003854,), validation=(111540,)\n"
     ]
    }
   ],
   "source": [
    "splitIdx = len(text) * 9 // 10\n",
    "trainData, validData = encode(text[:splitIdx]), encode(text[splitIdx:])\n",
    "print(f\"Shapes: train={trainData.shape}, validation={validData.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class BatchGenerator:\n",
    "    def __init__(self, data, batchSize, device=device):\n",
    "        self.data = data\n",
    "        self.batchSize = batchSize\n",
    "        self.device = device\n",
    "        self.nChars = len(data)\n",
    "        self.blockSize = cfg.block_size\n",
    "        self.maxRnd = self.nChars - self.blockSize - 1\n",
    "        self.random = random.Random()\n",
    "        self.xs = np.zeros([batchSize,self.blockSize], dtype=np.byte)\n",
    "        self.ys = np.zeros([batchSize,self.blockSize], dtype=np.byte)\n",
    "        self.tensorShape = [batchSize, self.blockSize]\n",
    "        self.charsServed = 0\n",
    "\n",
    "    def StartReproducibleRandom(self):\n",
    "        self.random = random.Random(1337)\n",
    "\n",
    "    def GetBatch(self):\n",
    "        for i in range(self.batchSize):\n",
    "            ix = self.random.randint(0, self.maxRnd)\n",
    "            #xdst = self.xs[i*self.blockSize:(i+1)*self.blockSize]\n",
    "            #xsrc = self.data[ix:ix+self.blockSize]\n",
    "            np.copyto(self.xs[i], self.data[ix:ix+self.blockSize])\n",
    "            ix = ix + 1\n",
    "            np.copyto(self.ys[i], self.data[ix:ix+self.blockSize])\n",
    "\n",
    "        self.charsServed += self.batchSize * self.blockSize\n",
    "\n",
    "        xb = torch.tensor(self.xs, dtype=torch.int64, device=self.device, requires_grad=False)\n",
    "        yb = torch.tensor(self.ys, dtype=torch.int64, device=self.device, requires_grad=False)\n",
    "        return xb, yb\n",
    "\n",
    "    @property\n",
    "    def Epoch(self):\n",
    "        return float(self.charsServed) / float(self.nChars)        \n",
    "    \n",
    "#bg = BatchGenerator(trainData, batchSize=4)\n",
    "#bg.GetBatch()\n",
    "#bg.Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flash sdp enabled = True\n",
      "Number of parameters: 154465\n"
     ]
    }
   ],
   "source": [
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "print(f\"Flash sdp enabled = {torch.backends.cuda.flash_sdp_enabled()}\")\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "\n",
    "model = LanguageModel(cfg.n_layer, cfg.n_head, cfg.n_embd, cfg.vocab_size, cfg.block_size)\n",
    "\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which model \n",
    "tmodel = model\n",
    "#tmodel = torch.jit.script(model)\n",
    "#tmodel = torch.jit.load(\"shakespeare.pt.zip\")\n",
    "\n",
    "# do you wish to compile it\n",
    "#tmodel = torch.compile(tmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"blah                            qjRimjgr;VnyIfTF&T&&uB\\nxOdvove\\neoVdqTrbw3ieK:QbBUGnxNTwWdyhyOrY VvvQCr?B&ko!\\n B:-W'QNyNBBBREwQISL TW\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(model, nTokens, input):\n",
    "    input = input.ljust(model.blockSize, ' ')\n",
    "    if len(input) != model.blockSize:\n",
    "        raise ValueError(f\"Expected input of length {model.blockSize}, got {len(input)}\")\n",
    "    idx = torch.tensor(encode(input).reshape(1,-1), dtype=torch.int64, device=device, requires_grad=False)\n",
    "    idx = idx.expand([2, -1])\n",
    "    idx = generateIxs(model, idx, nTokens)\n",
    "    idx = idx[0].cpu()\n",
    "    ords = [int(idx[i]) for i in range(idx.numel())]\n",
    "    return decode(ords)\n",
    "\n",
    "tmodel.to(device)\n",
    "generate(tmodel, 100, \"blah\") # should render some jibberish on untrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.352591514587402, 4.360431671142578)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evalLosses(model):\n",
    "    nLoops = 16\n",
    "    batchSize = 256\n",
    "    trainBatchGen = BatchGenerator(trainData, batchSize)\n",
    "    validBatchGen = BatchGenerator(validData, batchSize)\n",
    "    def getLoss(bg):\n",
    "        bg.StartReproducibleRandom()\n",
    "        losses = [get_loss(model,yb, model.forward(xb)) for i in range(nLoops) for xb, yb in [bg.GetBatch()]]\n",
    "        return torch.stack(losses).mean().item()\n",
    "    return getLoss(trainBatchGen), getLoss(validBatchGen)\n",
    "\n",
    "xb,yb = BatchGenerator(trainData,1).GetBatch()\n",
    "yHat = tmodel(xb)\n",
    "#cmodel.loss(yb, yHat)\n",
    "evalLosses(tmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select optimization features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = False\n",
    "#torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "#autocast_bfloat16_enabled = False\n",
    "autocast_bfloat16_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(tmodel.parameters(), lr=0.0001)\n",
    "\n",
    "batch_size = 384\n",
    "batchGen = BatchGenerator(trainData, batch_size)\n",
    "\n",
    "def _train(nSteps):\n",
    "    tmodel.train()\n",
    "    for step in range(nSteps+1):\n",
    "        xb, yb = batchGen.GetBatch()\n",
    "        yHat = tmodel.forward(xb)\n",
    "        loss = get_loss(tmodel, yb, yHat)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step % 5000 == 0 or step == nSteps-1:\n",
    "            tmodel.eval()\n",
    "            trainLoss, validLoss = evalLosses(tmodel)\n",
    "            print(f\"Step {step:5d}: loss={loss.item():6f} train={trainLoss:6f} valid={validLoss:6f} epoch={batchGen.Epoch:.2f}\")\n",
    "            tmodel.train()\n",
    "\n",
    "def train_with_autocast(nSteps):\n",
    "    with autocast(dtype=torch.bfloat16):\n",
    "        _train(nSteps)\n",
    "\n",
    "if autocast_bfloat16_enabled:\n",
    "    train = train_with_autocast\n",
    "else:\n",
    "    train = _train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0: loss=4.350426 train=4.351954 valid=4.359774 epoch=0.01\n",
      "Step  1999: loss=3.615506 train=3.641431 valid=3.659431 epoch=24.48\n",
      "w                                                                                                                                   \n"
     ]
    }
   ],
   "source": [
    "# warm up (for jit compiler)\n",
    "train(2000)\n",
    "\n",
    "print(generate(tmodel,100, \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step     0: loss=2719.273438 train=2724.448975 valid=2800.290771 epoch=24.51\n",
      "Step  5000: loss=42.836781 train=41.807877 valid=42.869843 epoch=85.71\n",
      "Step 10000: loss=4.046630 train=4.054552 valid=4.108221 epoch=146.91\n",
      "Step 15000: loss=3.439459 train=3.433811 valid=3.481143 epoch=208.12\n",
      "Step 20000: loss=3.211940 train=3.214323 valid=3.246267 epoch=269.32\n",
      "Step 25000: loss=3.077256 train=3.078688 valid=3.098293 epoch=330.53\n",
      "Step 30000: loss=2.933605 train=2.972079 valid=2.984072 epoch=391.73\n",
      "Step 35000: loss=2.888578 train=2.888368 valid=2.894849 epoch=452.93\n",
      "Step 40000: loss=2.823115 train=2.822555 valid=2.826303 epoch=514.14\n",
      "Step 45000: loss=2.761745 train=2.773122 valid=2.775843 epoch=575.34\n",
      "Step 49999: loss=2.735662 train=2.736983 valid=2.739197 epoch=636.54\n",
      "Step 50000: loss=2.713528 train=2.737242 valid=2.739402 epoch=636.55\n",
      "CPU times: user 3min 41s, sys: 668 ms, total: 3min 42s\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# do the actual training (measure time)\n",
    "\n",
    "train(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M                               EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE\n"
     ]
    }
   ],
   "source": [
    "print(generate(tmodel, 500, \"M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model...\n"
     ]
    }
   ],
   "source": [
    "# save the model if you were training base Model(), rather than a model loaded from file or compiled\n",
    "if tmodel == model:\n",
    "    print(\"saving model...\")\n",
    "    tmodel.to(torch.device(\"cpu\"))\n",
    "    tmodel.eval()\n",
    "    save_model = torch.jit.script(tmodel)\n",
    "    save_model.save(\"shakespeare.pt.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
